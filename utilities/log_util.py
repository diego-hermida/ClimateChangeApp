import errno
import logging

from logging.handlers import RotatingFileHandler
from os import makedirs, sep as os_file_separator
from sys import stdout

from utilities.util import get_config

__config = get_config(__file__)


def get_logger(path, name='RootLogger', level=logging.INFO, date_format=__config['LOG_DATE_FORMAT'],
               line_format=__config['LOG_RECORD_FORMAT'], to_stdout=False,
               stdout_level=logging.DEBUG) -> logging.Logger:
    """
    Configures a logging.Logger object.
    Log file maximum size is limited to MAX_LOG_FILE_SIZE. If max size is reached, current log file is closed and
    renamed to '{log file name}.1'. Next time MAX_LOG_FILE_SIZE is reached, a '{log file name}.2' will be created;
    and so on, until MAX_BACKUP_FILES are created. Oldest log file is deleted when MAX_BACKUP_FILES have been filled,
    and a new backup file is created.
    To see where log files are saved, read __get_log_filepath() documentation (log_util.py:54).
    :param path: Path of the calling module (expected: __file__ ).
    :param name: Logger's name.
    :param level: Minimum issue level to include log records into log file.
    :param date_format: Date format. Default format is 'dd-MM-yyyy hh:mm:ss.fff'
    :param line_format: Line format. Default format is '[<level>] <timestamp> <file:line @ threadName>: <message>'
    :param to_stdout: If True, prints log records to stdout.
    :param stdout_level: Stdout's issue level.
    :return: A logging.Logger object, configured and initialized with arguments.
    :rtype: logging.Logger
    """
    logger = logging.getLogger(name)
    formatter = logging.Formatter(line_format, datefmt=date_format)
    if to_stdout:
        stream_handler = logging.StreamHandler(stdout)
        stream_handler.setFormatter(formatter)
        stream_handler.setLevel(stdout_level)
        logger.addHandler(stream_handler)

    path = __get_log_filepath(path)
    __recursive_makedir(path[:path.rfind(os_file_separator)])

    file_handler = RotatingFileHandler(filename=path, maxBytes=__config['MAX_LOG_FILE_SIZE'],
                                       encoding=__config['LOG_FILE_ENCODING'], backupCount=__config['MAX_BACKUP_FILES'])
    file_handler.setFormatter(formatter)
    file_handler.setLevel(level)
    logger.addHandler(file_handler)

    return logger


def __recursive_makedir(path: str):
    """
    Recursively creates all directories under a base directory. If a directory does already exist, silently performs
    the operation (FileExistsError is handled).
    :param path: A valid directory path. Example: /var/log/DataGatheringSubsystem/data_modules, where 'data_modules' is
                 a directory (can be non-existent).
    :raise PermissionError: If an attempt to create a directory without the necessary privileges is made.
    """
    try:
        makedirs(path)
    except FileExistsError as ex:
        assert ex.errno == errno.EEXIST


def __get_log_filepath(path: str) -> str:
    """
    By convention, any log record generated by a module is stored in a file which is located under a base log directory,
    ROOT_LOG_FOLDER (log_util.config). To ease finding log files, paths from DataGatheringSubsystem's base directory are
    preserved. So, in order to get the log filepath of an arbitrary file, what we do is to append the  calling module's
    path from DataGatheringSubsystem's root folder to ROOT_LOG_FOLDER. Example:
            - ROOT_LOG_FOLDER: /var/log/DataGatheringSubsystem
            - Calling module: .../DataGatheringSubsystem/data_modules/historical_weather/historical_weather.py
            - Log file: /var/log/DataGatheringSubsystem/data_modules/historical_weather/historical_weather.log
    :param path: A <str> containing a valid path (see the example above).
    :return: The log file path of a file.
    """
    base = __config['ROOT_PROJECT_FOLDER'].split(os_file_separator)[-2]
    return __config['ROOT_LOG_FOLDER'] + path.split(base)[-1].replace('.py', '.log')
